%
% Exemplo LaTeX de monografia UNISINOS
%
% Elaborado com base nas orientações dadas no documento
% ``GUIA PARA ELABORAÇÃO DE TRABALHOS ACADÊMICOS''
% disponível no site da biblioteca da Unisinos.
% http://www.unisinos.br/biblioteca
%
% Os elementos textuais abaixo são apresentados na ordem em que devem
% aparecer no documento.  Repare que nem todos são obrigatórios - isso
% é devidamente indicado em cada caso.
%
% Comentários abaixo colocados entre aspas (`` '') foram
% extraídos diretamente do documento da biblioteca.
%
% Este documento é de domínio público.
%

%=======================================================================
% Declarações iniciais identificando a classe de documento e
% selecionando alguns pacotes adicionais.
%
% As opções disponíveis (separe-as com vírgulas, sem espaço) são:
% - twoside: Formata o documento para impressão frente-e-verso
%   (o default é somente-frente)
% - english,brazilian,french,german,etc.: idiomas usados no documento.
%   Deve ser colocado por último o idioma principal.
%=======================================================================
\documentclass[twoside,english,brazilian]{UNISINOSmonografia}
\usepackage[utf8]{inputenc} % charset do texto (utf8, latin1, etc.)
\usepackage[T1]{fontenc} % encoding da fonte (afeta a sep. de sílabas)
\usepackage{graphicx} % comandos para gráficos e inclusão de figuras
\usepackage{bibentry} % para inserir refs. bib. no meio do texto
\usepackage{longtable}
\usepackage[list=no]{caption} % Impede que a segunda tabela seja listada
\usepackage{makecell}



%=======================================================================
% Escolha do sistema para geração de referências bibliográficas.
%
% O default é usar o estilo unisinos.bst.  Comente a definição abaixo
% e descomente a linha seguinte para usar o estilo do ABNTeX (é
% necessário ter esse pacote instalado).
%
% A vantagem do unisinos.bst é que ele permite o uso de um arquivo .bib
% seguindo as orientações tradicionais do BibTeX (veja essas orientações
% em http://ctan.tug.org/tex-archive/biblio/bibtex/contrib/doc/btxdoc.pdf).
% Entretanto, o estilo não suporta algumas citações mais exóticas como
% apud.  Para isso, use o ABNTeX, mas esteja ciente de que muitas de
% suas referências serão incompatíveis com os estilos tradicionais do
% BibTeX como plain, alpha, ieeetr, entre outros.
%=======================================================================
\usepackage[alf]{abntex2cite}
%\usepackage[alf]{abntcite}

%=======================================================================
% Dados gerais sobre o trabalho.
%=======================================================================
\autor{Hoffmann}{André Felipe da Silva}
\titulo{Construção de Grafos de Conhecimento Educacional Orientada pela Taxonomia de Bloom com Modelos de Linguagem}

\orientador[Dra.]{Francisco}{Rosemary}

%\coorientador[Prof.~Dr.]{Lamport}{Leslie}

\unidade{Unidade Acadêmica de Graduação}
\curso{Curso de Bacharelado em Ciência da Computação}
\natureza{%
Monografia apresentada como requisito parcial para obtenção do título de Bacharel em Ciência da Computação, pelo Curso de Ciência da Computação da Universidade do Vale do Rio dos Sinos (UNISINOS)
}
\local{São Leopoldo}
\ano{2024}

% dados da ficha catalográfica
% (obrigatória somente para dissertações e teses)
%\cip{Dissertação (mestrado)}{004.732}
%\bibliotecario{Bibliotecária responsável: Fulana da Silva}{12/3456}

% cada palavra-chave deve ser fornecida duas vezes, uma em português e
% outra no idioma estrangeiro (na verdade, em tantos idiomas quantos se
% desejar).
\palavrachave{brazilian}{Grafos de Conhecimento}
\palavrachave{brazilian}{Aprendizado Adaptativo}
\palavrachave{brazilian}{Modelos de Linguagem}
\palavrachave{brazilian}{Taxonomia de Bloom}
\palavrachave{brazilian}{Unidades de Conhecimento}
\palavrachave{brazilian}{Educação Personalizada}
\palavrachave{english}{Knowledge Graphs}
\palavrachave{english}{Adaptive Learning}
\palavrachave{english}{Language Models}
\palavrachave{english}{Bloom's Taxonomy}
\palavrachave{english}{Knowledge Components}
\palavrachave{english}{Personalized Education}

%=======================================================================
% Início do documento.
%=======================================================================
\begin{document}
\capa
\folhaderosto
%\folhadeaprovacao % não deve ser incluída nos TCCs

%=======================================================================
% Resumo em Português.
%
% A recomendação é para 150 a 500 palavras.
%=======================================================================
\begin{abstract}
Este trabalho propõe uma metodologia para a construção automatizada de grafos de conhecimento educacional a partir de recursos como livros, artigos e vídeos. O sistema utiliza modelos de linguagem (LLMs) e algoritmos de grafos para extrair, organizar e classificar unidades de conhecimento (UCs), com o objetivo de gerar um grafo rico e adaptativo. A metodologia inclui etapas de processamento da linguagem natural, como segmentação de texto, extração de entidades e detecção de comunidades, além da aplicação da Taxonomia de Bloom para classificar as UCs em diferentes níveis cognitivos. O sistema gera um grafo de conhecimento que representa as relações entre os conceitos de forma clara e hierárquica, facilitando a navegação e a compreensão do conhecimento. A avaliação da dificuldade das UCs é realizada de forma comparativa, considerando a complexidade do conceito, o conhecimento prévio necessário e a clareza da linguagem. O sistema proposto utiliza LLMs para gerar estimativas iniciais de dificuldade e relações entre UCs, endereçando assim o problema do cold start em sistemas de aprendizado adaptativo e estabelecendo uma base que se adapta progressivamente conforme novos dados são coletados. Com base nesta capacidade adaptativa, o framework desenvolvido e fundamentado na Taxonomia de Bloom estabelece bases sólidas para expansões futuras, como a geração automatizada de exercícios específicos para cada nível cognitivo e o desenvolvimento de um sistema de recomendação de recursos complementares.
\end{abstract}

%=======================================================================
% Resumo em língua estrangeira (obrigatório somente para teses e
% dissertações).
%
% O idioma usado aqui deve necessariamente aparecer nos parâmetros do
% \documentclass, no início do documento.
%=======================================================================
\begin{otherlanguage}{english}
\begin{abstract}
This work proposes a methodology for the automated construction of educational knowledge graphs from resources such as books, articles, and videos. The system utilizes language models (LLMs) and graph algorithms to extract, organize, and classify knowledge components (KCs), aiming to generate a rich and adaptive graph. The methodology includes natural language processing steps such as text segmentation, entity extraction, and community detection, in addition to the application of Bloom's Taxonomy to classify KCs into different cognitive levels. The system generates a knowledge graph that represents the relationships between concepts in a clear and hierarchical way, facilitating navigation and knowledge understanding. The assessment of KC difficulty is performed comparatively, considering the complexity of the concept, the required prior knowledge, and the clarity of the language. The proposed system seeks to address the cold start problem in adaptive learning systems by utilizing LLMs to generate initial estimates of difficulty and relationships between KCs, establishing a basis for progressive adaptation as new data is collected. Building upon this adaptive capability, the developed framework, grounded in Bloom's Taxonomy, lays a solid foundation for future expansions, such as the automated generation of exercises specific to each cognitive level and the development of a complementary resource recommendation system.
\end{abstract}
\end{otherlanguage}

%=======================================================================
% Sumário
%=======================================================================
\tableofcontents

%=======================================================================
% Introdução
%=======================================================================
\chapter{Introdução}

Apesar do reconhecido potencial da educação personalizada, implementar sistemas de aprendizagem adaptativos na prática apresenta desafios significativos. Fechar a lacuna entre a pesquisa teórica e os aspectos práticos de criar sistemas escaláveis e adaptativos requer lidar com uma série de desafios complexos \cite{GOAT1}.  Esses sistemas precisam gerenciar eficientemente grandes quantidades de dados, incorporar novos conhecimentos e atender às diversas necessidades de alunos e educadores.

Modelos de domínio, que representam a estrutura fundamental e as relações entre os conceitos dentro de uma disciplina, são elementos chave para a construção de sistemas de aprendizagem adaptativa eficientes. Um aspecto-chave da modelagem de domínio é a definição de unidades de conhecimento (UC). Essas unidades representam os conceitos, habilidades ou procedimentos fundamentais que os alunos precisam dominar em um determinado assunto. As unidades de conhecimento são os blocos essenciais para recursos de aprendizagem adaptativa, incluindo recomendações personalizadas, visualização do progresso e caminhos de aprendizagem personalizados \cite{GOAT1}. No entanto, a construção de modelos de domínio eficazes apresenta desafios, como a necessidade de lidar com o problema de "cold start", que se refere à dificuldade em fornecer personalização no início da interação do aluno com o sistema devido à falta de dados sobre seu desempenho \cite{COLD_PROBLEM}.

Esta pesquisa propõe um sistema para gerar automaticamente modelos de domínio a partir de diversos recursos educacionais (por exemplo, livros didáticos, artigos, vídeos), definindo unidades de conhecimento e suas inter-relações. O sistema utiliza modelos de linguagem de grande porte (LLMs) para criar uma estrutura inicial que pode ser progressivamente refinada com dados de interação dos alunos.  Essa estratégia visa a oferecer suporte adaptativo desde o início da interação do aluno com a plataforma, mesmo quando dados de interação ainda são escassos.


\textbf{Problema de Pesquisa:} Como utilizar LLMs para automatizar a criação de modelos de domínio educacionais a partir de recursos diversos,  superando o problema de "cold start" e facilitando a personalização do aprendizado?

\textbf{Objetivo Geral:} Desenvolver um sistema automatizado para gerar modelos de domínio a partir de recursos educacionais diversos, utilizando LLMs para permitir o suporte adaptativo e progressivo ao aluno.

\textbf{Objetivos Específicos:}

\begin{enumerate}
    \item Criar um framework que permita a extração e organização automática de unidades de conhecimento a partir de materiais educacionais diversos, considerando diferentes níveis de complexidade cognitiva.
    \item Estabelecer um modelo baseado em LLMs para estimar inicialmente as relações de pré-requisito e dificuldade entre unidades de conhecimento.
    \item Implementar mecanismos que permitam o refinamento progressivo do modelo de domínio com base em dados de interação dos alunos.
    \item Demonstrar a viabilidade do sistema através de um estudo de caso aplicado a um domínio específico de conhecimento.
\end{enumerate}

A automatização da criação de grafos de conhecimento educacionais oferece um grande potencial para a área da educação. Ao facilitar a geração de modelos de domínio a partir de diferentes recursos, o sistema proposto pode auxiliar na criação de plataformas de aprendizagem adaptativa mais eficientes e personalizadas. A utilização de LLMs para a construção da estrutura inicial do modelo de domínio permite superar o problema de "cold start" e oferecer suporte desde o início da interação do aluno com a plataforma.

Para apresentar o desenvolvimento desta proposta, este trabalho está organizado em 5 capítulos. O Capítulo 2 apresenta a fundamentação teórica, abordando conceitos essenciais como dificuldade no contexto de aprendizado adaptativo, modelos de domínio, grafos de conhecimento, unidades de conhecimento (UCs), Taxonomia de Bloom e modelos de linguagem (LLMs). O Capítulo 3 discute os trabalhos relacionados, analisando diferentes abordagens para a construção de grafos de conhecimento educacional, detecção de pré-requisitos e estimativa de dificuldade. O Capítulo 4 detalha a metodologia proposta, incluindo a estrutura geral, as ferramentas utilizadas, o processo de construção do grafo de conhecimento e a validação inicial. Por fim, o Capítulo 5 apresenta o sistema proposto, descrevendo sua arquitetura, funcionalidades e perspectivas futuras.
%=======================================================================
% Escrevendo o Texto
%=======================================================================
\chapter{Fundamentação Teórica}
\section{Dificuldade no Contexto de Aprendizado Adaptativo}
A definição e modelagem da dificuldade de unidades de conhecimento é crucial em sistemas de aprendizado adaptativo. \citeonline{GOAT1} destaca a importância de definir adequadamente o nível de dificuldade dos componentes do conhecimento, pois isso afeta diretamente a personalização do aprendizado e a motivação do aluno. Imagine, por exemplo, um sistema de tutoria de matemática que apresenta a um aluno que ainda está aprendendo adição e subtração um problema envolvendo equações de segundo grau. Ao mesmo tempo, se o sistema apresentar a um aluno que já domina álgebra um problema como "1 + 1 = ?", ele pode se sentir entediado e desestimulado. Essa discrepância pode gerar frustração e desmotivação, levando o aluno a abandonar o sistema.

Em sistemas de aprendizado adaptativo, a dificuldade de cada unidade de conhecimento pode ser ajustada dinamicamente com base nos dados de interação dos alunos de forma contínua. Existem diferentes métodos para estimar a dificuldade, incluindo abordagens colaborativas, como a exemplificada em \citeonline{COLD_PROBLEM}, que utilizam dados de múltiplos alunos, e abordagens individualizadas, que concentram-se no desempenho individual de cada aluno. No entanto, mesmo as abordagens que utilizam dados de múltiplos alunos podem enfrentar o problema de "cold start", já que ainda é necessário algum nível de interação para que o sistema colete dados suficientes e forneça sugestões pertinentes. Ao utilizar LLMs para estimar a dificuldade das unidades de conhecimento, podemos oferecer uma experiência personalizada desde o início da interação do aluno com o sistema, mesmo quando dados de interação ainda são escassos.

\section{Modelo de Domínio e Grafo de Conhecimento}
O modelo de domínio é um componente essencial em sistemas de aprendizado adaptativo, pois define a estrutura conceitual do conhecimento que deve ser aprendido. Ele descreve os conceitos principais de uma área de estudo, suas características e as relações entre eles, permitindo que o sistema de aprendizado compreenda a progressão lógica dos tópicos. Conforme discutido por \citeonline{GOAT1}, a construção de um modelo de domínio envolve uma série de desafios e trade-offs. O autor destaca que a criação de um modelo de domínio deve equilibrar precisão e generalidade, garantindo que os conceitos sejam suficientemente específicos para suportar o aprendizado eficaz, mas não tão detalhados que se tornem inflexíveis ou impraticáveis de aplicar em um ambiente dinâmico.

No contexto de aprendizado adaptativo, um modelo de domínio precisa também lidar com o problema da complexidade crescente, pois incluir muitos detalhes pode dificultar a aplicação prática dos conceitos. Pelánek argumenta que uma boa modelagem de domínio deve levar em consideração tanto a acessibilidade quanto a utilidade prática, sendo flexível o suficiente para se adaptar a diferentes perfis de alunos.

Por outro lado, um grafo de conhecimento pode ser entendido como uma implementação prática do modelo de domínio. Enquanto o modelo de domínio estabelece a visão teórica das relações conceituais, o grafo de conhecimento organiza essas relações de forma visual e computacional, permitindo uma representação intuitiva e estruturada. Em um grafo, cada nó representa um conceito e as arestas indicam as conexões, como pré-requisitos ou relações de dependência. Dessa forma, o grafo de conhecimento não só materializa o modelo de domínio, mas também facilita o acesso e a navegação por essas informações, ajudando o sistema a compreender como guiar o aluno pelo conteúdo de forma eficaz.

Assim, enquanto o modelo de domínio oferece a base conceitual e estratégica sobre o que deve ser ensinado e como, o grafo de conhecimento fornece uma representação prática e navegável que pode ser utilizada pelo sistema de aprendizado para fornecer feedback e adaptar o conteúdo ao progresso do aluno.


\section{Unidade de Conhecimento (UC)}
A Unidade de Conhecimento é um componente central em modelos de domínio para aprendizado adaptativo. As UC representam blocos fundamentais do conhecimento que os alunos precisam dominar em um determinado campo. No contexto da teoria da aprendizagem e dos modelos educacionais, uma UC é definida como uma "unidade adquirida de função ou estrutura cognitiva", sendo inferida com base no desempenho do aluno em tarefas relacionadas \cite{Koedinger_1,GOAT2}.

\citeonline{GOAT1} destaca que, na construção de modelos de domínio, a definição de UC é uma tarefa que envolve uma série de nuances e desafios. Em um sistema adaptativo, é crucial que as UCs sejam definidas de forma que representem unidades funcionais do conhecimento — suficientemente granulares para permitir uma personalização eficaz, mas também suficientemente amplas para evitar a fragmentação excessiva do conteúdo. Esse equilíbrio é um dos principais desafios mencionados por Pelánek: a complexidade pode aumentar muito rapidamente se as UCs forem excessivamente detalhadas, dificultando a implementação prática e a navegação eficiente pelo conteúdo.

Além disso, Pelánek ressalta que as UCs não são apenas entidades isoladas; elas formam a base para determinar como o conhecimento pode ser representado e organizado em um modelo de domínio mais coeso. Por exemplo, cada UC pode ser conectada a outras UCs através de relações de pré-requisito, generalização-especialização ou até mesmo associações contextuais. No contexto do aprendizado adaptativo, isso significa que o sistema deve ser capaz de compreender não apenas quais UCs um aluno já dominou, mas também como essas UCs se relacionam entre si para facilitar a construção de um conhecimento progressivo e bem estruturado.

Portanto, ao definir UCs, o objetivo principal é garantir que o sistema possa utilizá-las efetivamente para guiar o aluno em um caminho de aprendizado coerente e adaptativo. Isso implica em considerar aspectos como\cite{GOAT1}:
\begin{itemize}

\item Granularidade: Cada UC deve ser granular o suficiente para capturar um aspecto relevante do conhecimento, mas não tão detalhada a ponto de complicar a estrutura do modelo de domínio.

\item Relacionamento entre UCs: Os tipos de relação que existem entre as UCs, como relações de pré-requisito (o que precisa ser aprendido antes) ou relações de suporte (o que facilita o aprendizado de outra UC), desempenham um papel fundamental na forma como o sistema recomenda atividades ou conteúdos.
\end{itemize}

Assim, as Unidades de Conhecimento servem não só para agrupar itens de aprendizagem relacionados, como "adição de frações" ou "capitalização de nomes próprios", mas também como elementos fundamentais para garantir a eficiência do aprendizado adaptativo, permitindo que o sistema navegue entre diferentes níveis de complexidade do conhecimento.

\section{Taxonomia de Bloom}
A Taxonomia de Bloom, originalmente desenvolvida por Benjamin Bloom e colaboradores em 1956 \cite{Bloom}, é uma estrutura fundamental na educação, auxiliando na categorização de objetivos educacionais em diferentes níveis de complexidade cognitiva. Essa taxonomia organiza as habilidades em uma hierarquia que se estende do básico - como memorizar fatos - ao complexo -  avaliar e criar novas ideias. Os níveis da Taxonomia de Bloom - Conhecimento, Compreensão, Aplicação, Análise, Síntese e Avaliação -  são amplamente utilizados para definir a progressão de habilidades que um aluno deve desenvolver ao longo de sua jornada educacional.

Em 2001, a taxonomia passou por uma revisão, resultando em uma estrutura mais dinâmica e focada nos processos cognitivos. Nessa versão revisada, os substantivos originais foram transformados em verbos, como lembrar, entender, aplicar, analisar, avaliar e criar, para melhor representar as ações mentais envolvidas em cada nível. Essa mudança facilita a aplicação da Taxonomia de Bloom em contextos de aprendizado adaptativo, permitindo uma definição mais precisa das habilidades e uma melhor personalização do aprendizado.\cite{Bloom}

No contexto desta pesquisa, a Taxonomia de Bloom revisada desempenha um papel importante na estruturação das Unidades de Conhecimento (UCs) que compõem o modelo de domínio. Ao classificar as UCs nos diferentes níveis da taxonomia, utilizando-a como uma heurística para guiar a expansão do grafo de conhecimento, podemos criar um grafo que reflita a progressão natural das habilidades e personalize a experiência de aprendizado.

A utilização de LLMs para gerar UCs complementares para cada nível da Taxonomia de Bloom garante que o grafo de conhecimento seja abrangente e completo, mesmo quando a UC principal extraída do material didático se concentra em apenas um nível da taxonomia. A Tabela \ref{table:bloom_exemple} apresenta exemplos de como o sistema pode gerar UCs complementares para a UC principal "Capital de Botswana", que se encaixa no nível "lembrar", expandindo para os outros níveis da Taxonomia de Bloom.

\begin{table}[h]
\centering
\caption{Unidades de Conhecimento geradas utilizando 'Capital de Botswana' como conceito base}
\begin{tabular}{|c|l|}
\hline
\textbf{Nível} & \textbf{Unidades de Conhecimento} \\ \hline
Lembrar & • Capital de Botswana \\ \hline
Compreender & • Compreender a importância da capital de Botswana no contexto do país. \\
 & • Descrever as funções e características de uma capital. \\ \hline
Aplicar & • Ser capaz de localizar a capital de Botswana em um mapa. \\
 & • Identificar a capital de Botswana em uma lista de cidades. \\ \hline
Analisar & • Comparar a capital de Botswana com outras capitais africanas, \\
 &  identificando semelhanças e diferenças. \\
 & • Analisar os fatores que influenciaram a escolha da capital \\
 &  de Botswana. \\ \hline
Avaliar & • Justificar a localização da capital de Botswana com base em \\
 &  critérios geográficos, políticos e sociais. \\
 & • Avaliar a importância da capital para o desenvolvimento de \\
 &  Botswana, considerando seus aspectos econômicos, \\
 &  sociais e culturais. \\ \hline
Criar & • Propor um projeto para melhorar a capital do país, considerando \\
 &  os desafios e oportunidades de desenvolvimento urbano. \\
 & • Elaborar um mapa da capital de Botswana, incluindo seus \\
 &  principais pontos turísticos e áreas de interesse. \\ \hline
\end{tabular}
\label{table:bloom_exemple}
\end{table}

\section{Modelos de Linguagem (LLMs)}

Modelos de Linguagem (LLMs) são modelos de inteligência artificial que, após treinamento em conjuntos massivos de dados de texto, demonstram notável capacidade na geração de texto, tradução de idiomas, escrita criativa e resposta a perguntas. Essa versatilidade no processamento da linguagem natural oferece um vasto potencial para diversas aplicações, incluindo a área educacional. Estudos recentes \cite{kojima2023largelanguagemodelszeroshot} demonstram que LLMs podem atuar como raciocinadores "zero-shot", operando com sucesso em tarefas complexas, como raciocínio aritmético e simbólico, sem necessidade de exemplos específicos. No presente trabalho, utilizamos prompts detalhados para guiar os LLMs na geração de Unidades de Conteúdo (UCs) e na avaliação da dificuldade, buscando demonstrar a viabilidade dessa abordagem. É importante notar que, para garantir a geração de UCs completas e informativas, prompts mais extensos são necessários, o que pode resultar em um maior número de tokens. Isso não foi considerado um problema, visto que o foco principal da pesquisa reside na demonstração do potencial da aplicação de LLMs na construção de grafos de conhecimento educacional.


\chapter{Trabalhos Relacionados}

A seção "Trabalhos Relacionados" tem como objetivo contextualizar a pesquisa e apresentar o contexto da pesquisa de construção de grafos de conhecimento educacionais. Para a seleção dos trabalhos aqui apresentados, foi utilizada uma abordagem exploratória, iniciando com a análise do artigo KnowEdu \cite{KNOWEDU}, que serviu como principal inspiração para o desenvolvimento da metodologia proposta. A partir do KnowEdu, a pesquisa se expandiu para abranger trabalhos que abordassem os seguintes tópicos:

\begin{itemize}
    \item Construção de grafos de conhecimento na área educacional;
    \item Uso da Taxonomia de Bloom na organização de informações educacionais;
    \item Modelos de linguagem para a extração e organização de informações;
    \item Estimativa de dificuldade de unidades de conhecimento;
    \item Mitigação do problema de "cold start" em sistemas adaptativos.
\end{itemize}

A seleção dos trabalhos se deu por meio de buscas em bases de dados acadêmicas, utilizando palavras-chave como "grafos de conhecimento", "educação", "Taxonomia de Bloom", "modelos de linguagem" e "aprendizado adaptativo". Além disso, foram considerados trabalhos que referenciavam o KnowEdu e outros artigos relevantes encontrados durante a pesquisa.



\section{Detecção de Pré-requisitos}

O KnowEdu\cite{KNOWEDU} foi um dos primeiros esforços significativos para automatizar a criação de grafos de conhecimento educacionais, enfrentando o problema de como identificar relações de pré-requisito entre conceitos de forma eficiente. O objetivo principal do KnowEdu era construir automaticamente essas relações a partir de textos curriculares e dados de avaliação dos alunos, permitindo a criação de um grafo que refletisse as dependências instrucionais entre os tópicos de ensino. Para alcançar isso, os autores empregaram uma metodologia baseada em técnicas de mineração de regras e aprendizado de máquina, utilizando redes neurais para rotular sequências e inferir padrões entre os conceitos. A abordagem mostrou-se eficaz ao identificar padrões de conhecimento que eram difíceis de modelar manualmente. No entanto, o KnowEdu depende de um volume mínimo de dados educacionais para gerar inferências precisas, principalmente nos estágios iniciais do sistema, o que limita sua aplicabilidade em contextos de escassez de dados, criando o problema "Cold Start" explicado anteriormente. O trabalho atual busca superar essa limitação ao utilizar LLMs para fornecer estimativas iniciais robustas das relações de pré-requisito, permitindo a construção do grafo de conhecimento mesmo quando há pouca ou nenhuma informação prévia disponível, aumentando a escalabilidade e a aplicabilidade da abordagem em diferentes contextos educacionais.

\section{Estimativa de Dificuldade}
O trabalho de \citeonline{COLD_PROBLEM} abordou a questão da estimativa da dificuldade dos itens de aprendizagem, com o objetivo de melhorar a experiência adaptativa dos alunos, ajustando o conteúdo ao nível de habilidade de cada um. Garantir uma estimativa precisa da dificuldade é crucial para evitar que os alunos se sintam sobrecarregados com tarefas excessivamente complexas ou subestimados por atividades simplistas, promovendo um aprendizado mais eficaz e um maior engajamento.

Para resolver esse problema, os autores propuseram diferentes estratégias de estimativa, variando entre abordagens colaborativas e individualizadas, que utilizavam fontes de dados variadas para prever a dificuldade dos itens. Essas abordagens permitiram avanços na precisão da estimativa da dificuldade, demonstrando que mesmo uma estimativa preliminar era significativamente mais eficaz do que a ausência de qualquer estimativa inicial ("Cold Start"). Esse resultado reforça a importância de fornecer estimativas iniciais para melhorar a adaptação dos conteúdos aos alunos.

A aplicação dessas estratégias é particularmente relevante para este trabalho, pois indica que estimativas iniciais, mesmo que imperfeitas, são fundamentais para criar um ponto de partida valioso para a personalização. Baseado nisso, o sistema proposto utiliza LLMs para fornecer essas estimativas preliminares de dificuldade, garantindo uma base adaptativa desde o início, mesmo em ambientes com escassez de dados de interação.

\section{Definição de Dependências com Base na Taxonomia de Bloom}
\citeonline{10.1007/978-3-030-63212-0_15} propuseram uma abordagem para identificar dependências entre resultados de aprendizagem utilizando a Taxonomia de Bloom como referência. O framework introduziu dois tipos fundamentais de relações: "REQUIRES", que estabelece hierarquias de pré-requisitos baseadas em níveis cognitivos, e "EXPANDS", que indica relações de complementaridade entre conceitos. Para identificar estas relações, os autores desenvolveram um processo de análise sintática e semântica dos resultados de aprendizagem, permitindo extrair automaticamente as conexões entre diferentes elementos curriculares.

A metodologia desenvolvida demonstrou como a Taxonomia de Bloom pode servir como base para estruturar relações entre componentes educacionais, estabelecendo tanto progressões hierárquicas de aprendizado quanto conexões laterais entre conceitos relacionados. O trabalho foi particularmente relevante ao mostrar que é possível automatizar parcialmente a identificação destas relações em currículos existentes, embora ainda exigindo considerável supervisão humana para validação.

No trabalho atual, adaptamos alguns destes conceitos, especialmente a utilização da Taxonomia de Bloom como estrutura organizadora e a distinção entre relações hierárquicas e de complementaridade, expandindo a abordagem para o contexto de geração automatizada de unidades de conhecimento.


\section{Organização e Respostas a Consultas com Grafos}
O GraphRAG\cite{GraphRAG} propõe uma solução inovadora para responder a perguntas complexas e globais em grandes coleções de documentos, abordando o problema de como gerar respostas abrangentes que vão além da recuperação de fragmentos específicos de texto. O objetivo do GraphRAG é estruturar e organizar o conhecimento contido nos documentos, de forma que perguntas amplas possam ser respondidas de maneira integrada e completa.

Para atingir esse objetivo, a metodologia empregada combina a geração aumentada por recuperação (RAG) com uma abordagem baseada em grafos para modelagem do conhecimento, utilizando o algoritmo Leiden para detectar comunidades dentro do grafo e aplicar uma abordagem de map-reduce para sintetizar respostas. Além disso, LLMs são utilizados para gerar descrições das comunidades detectadas, permitindo uma visão coesa e hierárquica dos tópicos tratados.

O GraphRAG se destaca por criar uma estrutura modular de conhecimento, capaz de responder de forma eficiente a perguntas globais. No trabalho atual, foi feita a adaptação desses conceitos para estruturar e hierarquizar unidades de conhecimento. O algoritmo Leiden foi utilizado para identificar módulos de conceitos relacionados, com cada comunidade detectada representando um grupo coeso de tópicos educacionais.

Os resumos gerados para cada grupo de conceitos são tratados como unidades de conhecimento de granularidade superior, criando uma hierarquia de abstração que facilita a navegação e a personalização do aprendizado. Dessa forma, enquanto o GraphRAG foca na organização e resposta a questões globais, o presente trabalho adapta esses conceitos para construir um grafo educacional dinâmico e hierárquico, adequado para a personalização do aprendizado em diferentes níveis de granularidade.

\section{Comparação dos Trabalhos Relacionados}

A Tabela \ref{tab:trabalhos_relacionados} apresenta uma análise comparativa dos trabalhos relacionados, destacando seus objetivos, métodos, contribuições e limitações. A análise crítica desses trabalhos fornece um panorama das lacunas existentes e direciona as contribuições da presente pesquisa.



\begin{longtable}{|p{2.5cm}|p{3cm}|p{3cm}|p{3cm}|p{3cm}|}
\caption{Tabela Comparativa dos Trabalhos Relacionados} \label{tab:trabalhos_relacionados} \\
\hline
\centering\textbf{Autor e Ano} & \centering\textbf{Objetivo} & \centering\textbf{Ferramentas / Abordagem} & \centering\textbf{Principais Contribuições} & \centering\textbf{Limitações / Lacunas} \\
\hline
\endfirsthead

\multicolumn{5}{c}%
{\tablename\ \thetable\ -- \textit{Continuação da página anterior}} \\
\hline
\textbf{Autor e Ano} & \textbf{Objetivo} & \textbf{Ferramentas/Abordagem} & \textbf{Principais Contribuições} & \textbf{Limitações/Lacunas} \\
\hline
\endhead

\hline \multicolumn{5}{r}{\textit{Continuação na próxima página}} \\
\endfoot

\hline
\endlastfoot

\citeonline{KNOWEDU} &
Criar um grafo de conhecimento a partir de currículos escolares. &
Algoritmos de mineração de regras e aprendizado de máquina. &
Estruturação eficiente de conceitos educacionais; Identificação de padrões de conhecimento. &
Depende de grandes volumes de dados; Problema de "Cold Start" em estágios iniciais. \\
\hline

\citeonline{COLD_PROBLEM} &
Estimar a dificuldade de unidades de conhecimento. &
Modelos baseados em dados históricos e diferentes estratégias de estimativa (colaborativas e individualizadas). &
Ajusta a dificuldade para melhorar a personalização; Demonstra a importância de estimativas iniciais. &
A abordagem ao problema de "Cold Start" não pode ser adaptada para unidades de conhecimento recém criadas e sem nenhum dado de iteração de alunos \\
\hline

\citeonline{10.1007/978-3-030-63212-0_15} &
Definir dependências entre resultados de aprendizagem. &
Taxonomia de Bloom Revisada; Relações "REQUIRES" e "EXPANDS". &
Framework para categorizar dependências entre UCs; Abordagem estruturada para representar hierarquia e complementaridade. &
Foco na definição de dependências, não na geração de UCs. \\
\hline

\citeonline{GraphRAG} &
Responder a perguntas complexas em grandes coleções de documentos. &
Geração aumentada por recuperação (RAG); Abordagem baseada em grafos; Algoritmo Leiden; LLMs para gerar descrições. &
Criação de uma estrutura modular de conhecimento; Respostas abrangentes a perguntas globais. &
Foco na recuperação de informações, não na personalização do aprendizado. \\
\hline

\end{longtable}









\chapter{Metodologia Implementada}
\label{chap:metodologia}

Este capítulo detalha a metodologia implementada para a construção automatizada de grafos de conhecimento educacional, conforme proposto no Trabalho de Conclusão de Curso I. O sistema resultante visa extrair, organizar e classificar unidades de conhecimento (UCs) a partir de diversos recursos textuais, utilizando Modelos de Linguagem de Grande Porte (LLMs) e algoritmos de grafos. A arquitetura foi concebida com foco em modularidade, orquestração robusta e gerenciamento eficiente de interações assíncronas com serviços externos, como os LLMs.

\section{Arquitetura Geral do Sistema}
\label{sec:arquitetura_geral}

A arquitetura do sistema implementado, ilustrada na Figura \ref{fig:componentes_alto_nivel} (Diagrama de Componentes de Alto Nível), organiza-se em torno de três grupos principais: o Usuário, o Sistema Central e a camada de Orquestração e Processamento Especializado.

\begin{figure}[htb]
    \centering
    \includegraphics[width=0.9\textwidth]{images/diagrama_componentes_alto_nivel.png}
    \caption{Diagrama de Componentes de Alto Nível do sistema proposto.}
    \label{fig:componentes_alto_nivel}
\end{figure}

O \textbf{Usuário} interage com o sistema primariamente através da \textbf{Pipeline API} (desenvolvida em FastAPI), que serve como o ponto central de controle para o upload de recursos, inicialização de execuções do pipeline (denominadas \textit{Pipeline Runs}) e consulta dos resultados. O \textbf{Sistema Central} também compreende o banco de dados \textbf{PostgreSQL}, responsável pela persistência de todos os dados de configuração, estado dos processos e artefatos gerados, e o acesso ao \textbf{Provedor LLM} (neste trabalho, a OpenAI API) para as tarefas de geração e avaliação de UCs. Um \textbf{Volume Compartilhado} é utilizado para o intercâmbio de arquivos entre os diferentes componentes, como os textos de entrada e os outputs intermediários.

A camada de \textbf{Orquestração e Processamento Especializado} é composta pelo \textbf{Orquestrador Airflow}, que gerencia o fluxo de execução das etapas do pipeline, e por um contêiner Docker dedicado para o \textbf{GraphRAG}, responsável pelo processamento inicial dos textos e extração da estrutura base de conhecimento. A Pipeline API orquestra as chamadas ao Airflow, que por sua vez executa as tarefas lógicas (que são, em grande parte, chamadas a endpoints específicos da própria Pipeline API) e o contêiner GraphRAG.

\section{Modelo de Dados e Persistência}
\label{sec:modelo_dados}

O sistema utiliza um banco de dados PostgreSQL para armazenar metadados, dados intermediários e os resultados finais do pipeline. A estrutura do banco de dados foi definida e evoluída através de migrações gerenciadas pelo Alembic. As principais entidades de dados estão detalhadas no Diagrama Entidade-Relacionamento (DER) apresentado no Apêndice \ref{apendice:der_completo}.

As tabelas centrais incluem:
\begin{itemize}
    \item \textit{PipelineRun}: Registra cada execução do pipeline, seu status, e os parâmetros de entrada.
    \item \textit{Resource} e \textit{PipelineRunResource}: Gerenciam os arquivos de entrada (materiais educacionais) e sua associação com cada \textit{PipelineRun}.
    \item \textit{PipelineBatchJob}: Tabela crucial para o gerenciamento do ciclo de vida das requisições em batch enviadas ao Provedor LLM. Armazena o ID do batch no provedor, o tipo de batch (geração de UCs ou avaliação de dificuldade), seu status atual (ex: \textit{PENDING\_SUBMISSION}, \textit{SUBMITTED}, \textit{COMPLETED}, \textit{FAILED}) e eventuais mensagens de erro. Esta tabela garante a idempotência e a rastreabilidade das interações assíncronas com o LLM.
    \item Tabelas \textit{graphrag\_*}: Um conjunto de tabelas (\textit{graphrag\_communities}, \textit{graphrag\_entities}, etc.) que armazenam os resultados brutos extraídos pelo processamento do GraphRAG para cada \textit{PipelineRun}.
    \item \textit{KnowledgeUnitOrigin}: Armazena as "origens" das UCs, que podem ser entidades ou resumos de comunidades identificadas pelo GraphRAG. Contém informações como título, contexto e nível hierárquico.
    \item \textit{GeneratedUcsRaw}: Persiste as UCs exatamente como foram geradas pelo LLM na etapa de geração, vinculadas à sua \textit{KnowledgeUnitOrigin}.
    \item \textit{DifficultyComparisonGroup} e \textit{DifficultyGroupOriginAssociation}: Estruturas de dados que registram os grupos de UCs (via suas origens) que foram comparadas entre si durante a etapa de avaliação de dificuldade, juntamente com o nível de coerência do grupo.
    \item \textit{KnowledgeUnitEvaluationsAggregatedBatch}: Armazena os resultados brutos da avaliação de dificuldade retornados pelo LLM para cada UC dentro de um grupo de comparação.
    \item \textit{FinalKnowledgeUnit} e \textit{FinalKnowledgeRelationship}: Representam o grafo de conhecimento educacional final, contendo as UCs processadas com seus scores de dificuldade agregados e as relações (REQUIRES, EXPANDS) entre elas.
\end{itemize}
Esta modelagem permite o rastreamento completo dos dados desde a entrada até a formação do grafo final, além de suportar a complexa lógica de interação com os serviços de LLM em batch.

\section{Fluxo de Processamento do Pipeline}
\label{sec:fluxo_processamento}

O pipeline de construção do grafo de conhecimento é orquestrado pelo Airflow, que coordena a execução de uma série de tarefas. A maioria dessas tarefas consiste em chamadas a endpoints específicos da Pipeline API, onde a lógica de processamento é efetivamente implementada. Este design centraliza a lógica de negócio na API, permitindo maior flexibilidade e testabilidade. O fluxo de dados e controle geral é ilustrado no Apêndice \ref{apendice:diagramas_fluxo}.

\subsection{Inicialização do Pipeline e Preparação dos Inputs}
\label{ssec:inicializacao_pipeline}
Uma nova execução do pipeline (\textit{PipelineRun}) é iniciada por uma chamada ao endpoint \url{POST /pipeline/{run_id}/init} da Pipeline API. Nesta chamada, o usuário fornece os IDs dos \textit{Resource} (materiais educacionais previamente carregados) que serão utilizados. A API registra a nova \textit{PipelineRun} no banco de dados e dispara o DAG correspondente no Airflow.

A primeira tarefa do DAG, \textit{prepare\_input\_files}, invoca um endpoint na API. A lógica deste endpoint (\textit{\_prepare\_input\_files\_callable}) é responsável por:
\begin{enumerate}
    \item Localizar os arquivos originais (PDFs, TXTs) no Volume Compartilhado, com base nos \textit{resource\_ids}.
    \item Converter arquivos PDF para formato TXT utilizando a biblioteca \textit{pypdfium2}. Arquivos TXT são mantidos como estão.
    \item Organizar os arquivos TXT resultantes em um diretório de entrada específico para a \textit{PipelineRun} corrente, dentro do Volume Compartilhado.
    \item Atualizar o status e o caminho do arquivo processado na tabela \textit{Resource}.
\end{enumerate}

\subsection{Processamento com GraphRAG}
\label{ssec:processamento_graphrag}
Esta tarefa utiliza um contêiner Docker configurado com a ferramenta GraphRAG. O contêiner lê os arquivos TXT preparados na etapa anterior (do diretório de input da run no Volume Compartilhado) e executa seu pipeline de indexação padrão. Esse processo envolve chunking de texto, extração de entidades e relações, resolução de entidades, detecção de comunidades (utilizando o algoritmo Leiden) e geração de resumos para essas comunidades. Os outputs do GraphRAG (arquivos Parquet como \textit{communities.parquet}, \textit{entities.parquet}, \textit{relationships.parquet}, etc.) são salvos em um diretório de output específico da \textit{PipelineRun} no Volume Compartilhado.

\subsection{Preparação das Origens de Conhecimento}
\label{ssec:preparacao_origens}
Após a conclusão do GraphRAG, a task \textit{prepare\_origins} do Airflow chama o endpoint \url{POST /pipeline/{run_id}/prepare-origins} da API. A lógica associada (\textit{task\_prepare\_origins}) realiza as seguintes ações:
\begin{enumerate}
    \item Carrega os arquivos Parquet gerados pelo GraphRAG.
    \item Processa o arquivo \textit{communities.parquet} para identificar a relação pai-filho entre comunidades.
    \item Enriquece os dados das entidades (do \texttt{entities.parquet}) com o ID da comunidade à qual pertencem, utilizando os mapeamentos gerados nas etapas anteriores.
    \item Popula as tabelas \textit{graphrag\_*} no banco de dados com os dados processados dos Parquets.
    \item Finalmente, cria os registros na tabela \textit{KnowledgeUnitOrigin}. As origens são derivadas tanto das entidades individuais quanto dos resumos das comunidades do GraphRAG. Cada \textit{KnowledgeUnitOrigin} armazena o título, contexto (descrição da entidade ou resumo da comunidade) e informações hierárquicas (como \textit{level} e \textit{parent\_community\_id\_of\_origin}).
\end{enumerate}
Estas \texttt{KnowledgeUnitOrigin} servem como base para a subsequente geração de Unidades de Conhecimento.





\subsection{Geração de Unidades de Conhecimento (UCs)}
\label{ssec:geracao_ucs}
A geração de UCs é iniciada pela task \textit{submit\_generation\_batch} do Airflow, que chama o endpoint
\url{POST /pipeline/{run_id}/submit-batch/uc_generation} da API, que executa os seguintes passos:
\begin{enumerate}
    \item Recupera as \textit{KnowledgeUnitOrigin} do banco de dados para a \textit{PipelineRun} atual.

    \item Para cada origem selecionada, formata um prompt específico para o LLM (conforme Apêndice \ref{apendice:prompt_ucs}, que instrui a geração de UCs para os seis níveis da Taxonomia de Bloom Revisada, utilizando o título e o contexto da origem).
    \item Cria um registro na tabela \textit{PipelineBatchJob} com \textit{batch\_type='uc\_generation'} e status inicial \textit{PENDING\_SUBMISSION}.
    \item Envia as requisições formatadas como um batch para o Provedor LLM (OpenAI Batch API). O ID do batch retornado pelo provedor é armazenado no registro \textit{PipelineBatchJob}.
\end{enumerate}
A interação detalhada com a API de Batch do LLM, incluindo o upload do arquivo de requisições e a criação do job, é encapsulada pela classe \texttt{LLMClient} e segue o ciclo de vida ilustrado no Apêndice \ref{apendice:batch_lifecycle}



Após a submissão, a task \textit{wait\_generation\_batch\_completion} do Airflow (um \textit{HttpSensor}) monitora periodicamente o status do batch chamando o endpoint \url{GET /pipeline/{run_id}/batch-job-status/uc_generation}. Este endpoint, por sua vez, consulta o Provedor LLM e atualiza o status do \textit{PipelineBatchJob} no banco de dados (ex: para \textit{SUBMITTED}, \textit{COMPLETED}, \textit{FAILED}).

Quando o batch é concluído pelo LLM, a task \textit{process\_generation\_batch\_results} do Airflow chama o endpoint
\url{POST /pipeline/{run_id}/process-batch-results/uc_generation}. Esta baixa o arquivo de resultados do Provedor LLM, processa cada linha (que contém a resposta para uma origem), extrai as UCs geradas para cada nível de Bloom, e salva esses dados na tabela \textit{GeneratedUcsRaw}. O status do \textit{PipelineBatchJob} é então atualizado para \textit{COMPLETED}.

\subsection{Definição de Relações entre UCs}
\label{ssec:definicao_relacoes}
Com as UCs brutas geradas, a task \texttt{define\_relationships} do Airflow chama o endpoint \url{POST /pipeline/{run_id}/define-relationships} da API, que constrói as seguintes relações entre as UCs:
\begin{itemize}
    \item \textbf{Relações REQUIRES}: São criadas entre UCs geradas a partir da mesma \textit{KnowledgeUnitOrigin}. Especificamente, uma UC de um nível da Taxonomia de Bloom (ex: Entender) "requer" a UC do nível imediatamente anterior (ex: Lembrar) da mesma origem.
    \item \textbf{Relações EXPANDS}: São criadas entre UCs de \textit{diferentes} \textit{KnowledgeUnitOrigin}, mas cujas origens (sejam entidades ou comunidades) possuem uma relação preexistente identificada pelo GraphRAG. Por exemplo, se a Entidade A está relacionada à Entidade B no grafo do GraphRAG, então as UCs de nível "Lembrar" e "Entender" da Entidade A "expandem" para as UCs correspondentes da Entidade B.
\end{itemize}
Estas relações são construídas utilizando um padrão Builder (\textit{RequiresBuilder} e \textit{ExpandsBuilder}) e salvas na tabela \textit{KnowledgeRelationshipIntermediate}.


\subsection{Avaliação de Dificuldade das UCs}
\label{ssec:avaliacao_dificuldade}
A avaliação da dificuldade das UCs segue um processo similar à geração de UCs, também utilizando a API de Batch do LLM. A task \textit{submit\_difficulty\_batch} do Airflow chama o endpoint
\url{POST /pipeline/{run_id}/submit-batch/difficulty_assessment}, que é responsável por:
\begin{enumerate}
    \item Utilizar o \textit{OriginDifficultyScheduler} para formar grupos de comparação. Este scheduler tenta agrupar \textit{KnowledgeUnitOrigin} que são contextualmente próximas (mesma comunidade pai) e que ainda não atingiram um número mínimo de avaliações. O processo de formação de grupos é detalhado no apendice \ref{apendice:diagrama_dificuldade_apendice_ref}.
    \item Para cada grupo de comparação e para cada nível da Taxonomia de Bloom, selecionar as UCs correspondentes (da tabela \textit{GeneratedUcsRaw}).
    \item Formatar um prompt específico para o LLM (conforme Apêndice \ref{apendice:prompt_dificuldade}), instruindo-o a avaliar comparativamente a dificuldade das UCs fornecidas (em uma escala de 0-100) e fornecer uma justificativa.
    \item Criar um registro na tabela \textit{DifficultyComparisonGroup} para cada conjunto de UCs enviado ao LLM, armazenando metadados como o nível de Bloom e o nível de coerência do grupo. As associações entre os grupos e as origens das UCs são salvas em \textit{difficulty\_group\_origin\_association}.
    \item Criar um registro na tabela \textit{PipelineBatchJob} com \textit{batch\_type='difficulty\_assessment'} e submeter o batch ao Provedor LLM.
\end{enumerate}

Similarmente à geração de UCs, a task \textit{wait\_difficulty\_batch\_completion} monitora o progresso, e \textit{process\_difficulty\_batch\_results} (chamando \textit{task\_process\_difficulty\_batch} na API) processa os resultados. As avaliações de dificuldade retornadas pelo LLM para cada UC (incluindo score e justificativa) são salvas na tabela \textit{KnowledgeUnitEvaluationsAggregatedBatch}, vinculadas ao \textit{comparison\_group\_id} correspondente. O ciclo de vida da interação com o LLM Batch API (Apêndice \ref{apendice:batch_lifecycle}) também se aplica aqui.




\subsection{Finalização e Geração dos Outputs}
\label{ssec:finalizacao_outputs}
A última etapa do pipeline é executada pela task \textit{finalize\_outputs} do Airflow, que chama o endpoint \url{/pipeline/{run_id}/finalize-outputs}, que:
\begin{enumerate}
    \item Carrega as UCs da \textit{GeneratedUcsRaw} e todas as avaliações de dificuldade da \textit{KnowledgeUnitEvaluationsAggregatedBatch}.
    \item Para cada UC, calcula o score final de dificuldade como a média dos scores recebidos nas diversas avaliações em que participou. O número de avaliações e a concatenação das justificativas também são registrados.
    \item Salva as UCs, agora enriquecidas com o score de dificuldade, na tabela \textit{FinalKnowledgeUnit}.
    \item Copia as relações da \textit{KnowledgeRelationshipIntermediate} para a tabela \textit{FinalKnowledgeRelationship}.
    \item Atualiza o status da \textit{PipelineRun} no banco de dados para \textit{success}.
\end{enumerate}
Ao final deste processo, o grafo de conhecimento educacional está construído e pronto para ser consultado através dos endpoints da API.

\section{Ferramentas e Tecnologias Utilizadas}
\label{sec:ferramentas_tecnologias}
O desenvolvimento do sistema proposto envolveu o uso de um conjunto de ferramentas e tecnologias, incluindo:
\begin{itemize}
    \item \textbf{Linguagem de Programação:} Python 3.10.
    \item \textbf{Framework API:} FastAPI.
    \item \textbf{ORM e Banco de Dados:} SQLAlchemy e PostgreSQL; Alembic para migrações.
    \item \textbf{Orquestração de Pipeline:} Apache Airflow.
    \item \textbf{Processamento de Texto e Grafos:} GraphRAG (Microsoft).
    \item \textbf{Modelos de Linguagem (LLMs):} OpenAI API (Batch API, \textit{gpt-4o-mini}).
    \item \textbf{Manipulação de Dados:} Pandas.
    \item \textbf{Conteinerização:} Docker e Docker Compose.
    \item \textbf{Processamento de PDF:} Biblioteca \textit{pypdfium2}.
\end{itemize}

%=======================================================================
% Validação Inicial / Resultados (Este seria o seu novo capítulo)
%=======================================================================
\chapter{Resultados e Análise} % Ou "Validação e Resultados"
\label{chap:resultados}

% Nesta seção, você descreverá:
% 1. O estudo de caso que você executou (ex: o livro de história).
% 2. Estatísticas do grafo gerado (número de UCs, relações, origens, etc.).
% 3. Exemplos de UCs geradas para diferentes níveis de Bloom.
% 4. Análise da qualidade das UCs e relações (com base nos critérios que você definiu).
% 5. Análise dos scores de dificuldade.
% 6. Desafios encontrados e limitações da implementação atual.
% 7. Discussão sobre a eficácia em mitigar o "cold start".

Este capítulo apresenta os resultados obtidos com a aplicação da metodologia descrita a um estudo de caso prático, utilizando o domínio de História com foco em temas do Ensino Médio. A análise visa validar a capacidade do sistema em gerar automaticamente um grafo de conhecimento educacional estruturado e avaliar a qualidade dos artefatos produzidos.

\section{Configuração do Estudo de Caso}
Para a validação inicial, o sistema foi alimentado com o livro "A História do Mundo Para Quem Tem Pressa" de Emma Marriott, em formato TXT. Este material foi escolhido por sua abrangência temática e estrutura narrativa, adequadas para testar a extração de conceitos e a geração de unidades de conhecimento em múltiplos níveis de complexidade. A execução do pipeline utilizou o modelo \textit{gpt-4o-mini} da OpenAI para as tarefas de geração de UCs e avaliação de dificuldade.

\section{Análise Quantitativa do Grafo Gerado}
A execução do pipeline sobre o material de entrada resultou na geração de um grafo de conhecimento com as seguintes características (exemplo, substitua pelos seus dados reais):
\begin{itemize}
    \item Número total de \textit{KnowledgeUnitOrigin} identificadas: XXX
    \item Número total de \textit{GeneratedUcsRaw} (UCs brutas): YYY (aproximadamente 6 por origem)
    \item Número de grupos de comparação para dificuldade (\textit{DifficultyComparisonGroup}): ZZZ
    \item Número total de avaliações de dificuldade individuais (\textit{KnowledgeUnitEvaluationsAggregatedBatch}): WWW
    \item Número total de \textit{FinalKnowledgeUnit} (UCs finais com score): YYY
    \item Número total de relações \textit{REQUIRES} em \textit{FinalKnowledgeRelationship}: RRR
    \item Número total de relações \textit{EXPANDS} em \textit{FinalKnowledgeRelationship}: EEE
\end{itemize}
Estes números demonstram a capacidade do sistema de processar o texto e expandi-lo em uma estrutura de conhecimento granular.

% ... (Continue com as outras seções de Resultados e Análise) ...

%=======================================================================
% Conclusão (Você escreveria uma nova conclusão para o TCC II)
%=======================================================================
\chapter{Conclusão}
\label{chap:conclusao}

% Resumir o trabalho, os principais resultados, as contribuições,
% as limitações e as direções para trabalhos futuros.

%=======================================================================
% Referências (Mantém as referências do TCC I, adicione novas se houver)
%=======================================================================
\bibliography{exemplo} % Ou o nome do seu arquivo .bib

%=======================================================================
% Apêndices (Mantém os apêndices originais do TCC I sobre prompts)
% E adiciona os novos para os diagramas.
%=======================================================================
\appendix % Comando para iniciar os apêndices



\chapter{Prompt para Geração de UCs} \label{apendice:prompt_ucs}
O prompt a seguir foi elaborado para guiar o modelo de linguagem na geração de UCs. Ele inclui uma breve explicação sobre o que são UCs e a Taxonomia de Bloom Revisada, além de instruções claras sobre a tarefa a ser realizada, com ênfase na utilização dos verbos da taxonomia e na relação entre as UCs e o conceito principal. A estrutura do prompt tenta maximizar a capacidade do modelo de linguagem de gerar UCs relevantes, completas e personalizadas para cada conceito. \textbf{Conforme discutido na seção sobre LLMs, a otimização do número de tokens não foi priorizada na elaboração deste prompt, visando, neste momento, apenas a validação da viabilidade da tarefa.} \\

PROMPT:

\begin{quote}

Você é um especialista em educação, capaz de gerar Unidades de Conhecimento (UCs) abrangentes e personalizadas com base na Taxonomia de Bloom Revisada.

\textbf{O que é uma UC?}

Uma UC representa um conceito, habilidade ou informação que um aluno deve aprender. As UCs podem variar em complexidade, desde a simples memorização de um fato até a aplicação do conhecimento em situações complexas e a criação de algo novo.

\textbf{O que é a Taxonomia de Bloom Revisada?}

A Taxonomia de Bloom Revisada é uma estrutura que classifica os objetivos de aprendizagem em seis níveis cognitivos:

\begin{enumerate}
\item \textbf{Lembrar:} reconhecer e reproduzir informações. \\
Verbos: identificar, listar, descrever, nomear, rotular, localizar, selecionar, definir, recitar, delinear, declarar, repetir, memorizar, enunciar, registrar.
\item \textbf{Entender:} interpretar, exemplificar, classificar, resumir, inferir, comparar e explicar informações. \\
Verbos: explicar, resumir, parafrasear, classificar, exemplificar, converter, traduzir, ilustrar, demonstrar, apresentar, fornecer exemplos, mostrar, categorizar, organizar, agrupar, diferenciar, distinguir, sintetizar, condensar, encurtar, recapitular, compendiar, concluir, deduzir, interpretar, extrapolar, interpolar, comparar, contrastar, relacionar, analisar, distinguir, descrever, discutir, esclarecer, interpretar, justificar.
\item \textbf{Aplicar:} executar e implementar o conhecimento em situações novas. \\
Verbos: realizar, implementar, aplicar, usar, empregar, manipular, operar, construir, desenvolver, simular, projetar, experimentar, solucionar.
\item \textbf{Analisar:} diferenciar, organizar, atribuir e concluir sobre as partes e relações de uma informação. \\
Verbos: discriminar, distinguir, separar, comparar, contrastar, estruturar, sequenciar, integrar, classificar, delinear, esquematizar, determinar, conectar, relacionar, identificar, analisar, encontrar, deduzir, inferir, derivar, interpretar, justificar, explicar.
\item \textbf{Avaliar:} checar e criticar a informação com base em critérios. \\
Verbos: testar, validar, verificar, controlar, monitorar, examinar, inspecionar, julgar, argumentar, justificar, defender, questionar, avaliar, recomendar.
\item \textbf{Criar:} generalizar, planejar e produzir algo novo a partir do conhecimento. \\
Verbos: formular, construir, desenvolver, criar, projetar, produzir, compor, organizar, esquematizar, desenhar, estruturar, propor, estabelecer, idealizar, gerar, construir, inventar, compor, criar, desenvolver, originar.
\end{enumerate}

\textbf{Sua tarefa:}

Com base no conceito fornecido, gere UCs complementares que explorem os seis níveis da Taxonomia de Bloom Revisada.

\textbf{Observações:}

\begin{itemize}
\item Utilize os verbos da Taxonomia de Bloom Revisada para formular as UCs complementares.
\item Assegure-se de que as UCs complementares estejam relacionadas ao conceito principal.
\end{itemize}

\textbf{Número de UCs por nível:} \{\{Número de UCs desejadas\}\}

\textbf{Contexto:} (Necessário para garantir desambiguação entre conceitos similares) \\
\{\{resumo criado para à comunidade agrupada pelo algorítimo de leiden\}\}

\textbf{Conceito:} \\
\{\{UC avaliada\}\}

\end{quote}




% \appendix
\chapter{Prompt para definição da dificuldade} \label{apendice:prompt_dificuldade}

O prompt a seguir foi elaborado para guiar o modelo de linguagem na avaliação da dificuldade das UCs. Ele inclui uma breve explicação sobre o que são UCs, os critérios a serem considerados na avaliação da dificuldade e instruções claras sobre a tarefa a ser realizada. A estrutura do prompt foi projetada para auxiliar o modelo de linguagem a fornecer avaliações consistentes com os objetivos do sistema. \textbf{Conforme discutido na seção sobre LLMs, a otimização do número de tokens não foi priorizada na elaboração deste prompt, visando, neste momento, apenas a validação da viabilidade da tarefa.} \\

PROMPT:
\begin{quote}
Você é um especialista em educação, capaz de analisar unidades de conhecimento (UCs) e determinar o seu nível de dificuldade.

Uma UC representa um conceito, habilidade ou informação que um aluno deve aprender. As UCs podem variar em complexidade, desde a simples memorização de um fato até a aplicação do conhecimento em situações complexas.

Sua tarefa é avaliar a dificuldade das UCs a seguir em uma escala de 0 a 100, onde 0 representa 'muito fácil' e 100 'muito difícil'. Leve em consideração os seguintes critérios ao determinar a dificuldade:

\begin{itemize}
\item Complexidade do conceito: conceitos abstratos e multifacetados são mais difíceis de aprender do que conceitos simples e concretos.
\item Habilidades cognitivas necessárias: UCs que exigem análise, síntese ou avaliação são mais difíceis do que aquelas que exigem apenas memorização ou compreensão.
\item Conhecimento prévio necessário: UCs que exigem conhecimento prévio de outros conceitos são mais difíceis do que aquelas que podem ser aprendidas isoladamente.
\item Clareza da linguagem: UCs escritas em linguagem clara e concisa são mais fáceis de aprender do que aquelas com linguagem complexa ou ambígua.
\end{itemize}

\textbf{UCs a serem avaliadas:}

\{\{lista de UCs separadas por bullet points\}\}

\textbf{Resposta:}

Avalie a dificuldade de cada UC em uma escala de 0 a 100 e justifique sua resposta com base nos critérios fornecidos.

\textbf{Observações:}

\begin{itemize}
\item Evite dar a mesma nota para todas as UCs.
\item Utilize todo o espectro da escala de 0 a 100 para avaliar as UCs.
\item Assegure-se de que suas avaliações sejam consistentes e imparciais.
\item Lembre-se de que você é um especialista em educação e suas avaliações devem refletir sua expertise.
\end{itemize}

\end{quote}







\chapter{Diagrama Entidade-Relacionamento (DER) do Sistema}
\label{apendice:der_completo}

A Figura \ref{fig:diagrama_entidades_ap} apresenta o Diagrama Entidade-Relacionamento (DER) detalhado do banco de dados utilizado pelo sistema.

\begin{figure}[H] % Usando [H] do pacote float para tentar forçar a posição
    \centering
    % Tente ajustar height e width. Se a imagem for muito larga, rotacionar pode ser melhor.
    % Se for muito alta, reduza o height.
    \includegraphics[width=\textwidth, height=0.8\textheight, keepaspectratio]{images/diagrama_entidades.png}
    \caption{Diagrama Entidade-Relacionamento do banco de dados do sistema.}
    \label{fig:diagrama_entidades_ap}
\end{figure}
% % Alternativa com rotação se o DER for muito largo:
% \begin{sidewaysfigure}
%     \centering
%     \includegraphics[width=0.9\textheight, keepaspectratio]{images/diagrama_entidades.png} % Note width = 0.9 da altura da página
%     \caption{Diagrama Entidade-Relacionamento do banco de dados do sistema (rotacionado).}
%     \label{fig:diagrama_entidades_ap_rot}
% \end{sidewaysfigure}


\clearpage
\chapter{Diagramas de Fluxo de Processamento do Pipeline}
\label{apendice:diagramas_fluxo}

As Figuras \ref{fig:fluxo_dados_1_ap} e \ref{fig:fluxo_dados_2_ap} ilustram o fluxo de dados e controle do pipeline de construção do grafo de conhecimento.

\begin{figure}[H]
    \centering
    \begin{minipage}{0.25\textwidth}
        \centering
        \includegraphics[width=\linewidth, maxheight=0.7\textheight, keepaspectratio]{images/diagrama_fluxo_de_dados_1.png}
        \label{fig:fluxo_dados_1_ap}
    \end{minipage}\hfill
    \begin{minipage}{0.25\textwidth}
        \centering
        \includegraphics[width=\linewidth, maxheight=0.7\textheight, keepaspectratio]{images/diagrama_fluxo_de_dados_2.png}
        \label{fig:fluxo_dados_2_ap}
    \end{minipage}
    \caption{Diagrama de Fluxo de Dados do Pipeline (Parte 1 e Parte 2).}
    \label{fig:fluxo_dados_conjunto_ap}
\end{figure}

\clearpage
\chapter{Diagrama de Sequência do Ciclo de Vida de Batch LLM}
\label{apendice:batch_lifecycle}

A Figura \ref{fig:batch_lifecycle_ap} detalha a interação assíncrona com o Provedor LLM para a submissão e monitoramento de jobs em batch.

\begin{figure}
    \centering
    \includegraphics[width=0.9 \textwidth, maxheight=0.55\textheight, keepaspectratio]{images/diagrama_sequencia_batch_lifecicle.png}
    \caption{Diagrama de Sequência do Ciclo de Vida de Batch LLM.}
    \label{fig:batch_lifecycle_ap}
\end{figure}

\clearpage
\chapter{Fluxograma do Agendador de Dificuldade de Origens}
\label{apendice:diagrama_dificuldade_apendice_ref} % Nova label para evitar conflito

A Figura \ref{fig:dificuldade_scheduler_ap} ilustra a lógica utilizada pelo \textit{OriginDifficultyScheduler} para formar grupos de comparação para a avaliação de dificuldade das UCs.

\begin{figure}
    \centering
    \includegraphics[width=0.65 \textwidth, maxheight=0.55\textheight, keepaspectratio]{images/diagrama_dificuldade.png}
    \caption{Fluxograma da lógica do Agendador de Dificuldade de Origens.}
    \label{fig:dificuldade_scheduler_ap}
\end{figure}


\end{document}
